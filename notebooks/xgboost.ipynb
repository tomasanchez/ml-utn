{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7376dab3cb04c7",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "## Example\n",
    "\n",
    "- Does a specific image contain a person's face?\n",
    "- Training data: vectors of pixel values\n",
    "- Labels: 1 or 0\n",
    "\n",
    "## Classification Problems\n",
    "\n",
    "### Binary classification\n",
    "\n",
    "> Will a person purchase the insurance package given some quote?\n",
    " \n",
    "**AUC**: Metric for binary classification models.\n",
    "\n",
    "- Area under the ROC curve (AUC)\n",
    "- Larger area under the ROC curve = better model\n",
    "\n",
    "### Multi-class classification\n",
    "\n",
    "> What is the species of a given bird?\n",
    "\n",
    "Accuracy score and confusion matrix are common metrics.\n",
    "\n",
    "- Confusion matrix\n",
    "\n",
    "\n",
    "|      Actual      | Predicted: Spam Email | Predicted: Real Email |\n",
    "|:----------------:|:---------------------:|:---------------------:|\n",
    "|    Spam Email    |     True Positive     |    False Positive     |\n",
    "|    Real Email    |    False Positive     |     True Positive     |\n",
    "\n",
    "\n",
    "- Accuracy\n",
    "\n",
    "$$\\frac{tp + tn}{tp + tn + fp + fn}$$\n",
    "\n",
    "Other supervised learning considerations\n",
    "- Features (Also known as Attributes or Predictors) can be either numeric or categorical\n",
    "- Numeric features should be scaled (Z-scored)\n",
    "- Categorical features should be encoded (One-hot encoding)\n",
    "\n",
    "**Ranking problems**\n",
    "- Predicting an ordering on a set of choices\n",
    "\n",
    "**Recommendation problems**\n",
    "- Recommending a product or service to a user\n",
    "- Based on consumption history and profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af04d9956595e0",
   "metadata": {},
   "source": [
    "## What is XGBoost\n",
    "\n",
    "- Optimized gradient-boosting machine learning library\n",
    "- Originally written in C++\n",
    "- Has APIs in several languages:\n",
    "   - **Python**\n",
    "   - R\n",
    "   - Julia\n",
    "   - Scala\n",
    "   - Java\n",
    "\n",
    "### What makes XGBoost so popular?\n",
    "\n",
    "- Speed and performance\n",
    "- Core algorithm is parallelizable\n",
    "- Consistently outperforms other single-algorithm methods\n",
    "- State-of-the-art performance in many ML tasks\n",
    "\n",
    "### Using XGBoost: a quick example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8119dde606bc41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "class_data = pd.read_csv('class_data.csv')\n",
    "# Split the entire dataset into features (X) and target (y)\n",
    "X, y = class_data.iloc[:, :-1], class_data.iloc[:, -1]\n",
    "# Split the dataset into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "# Instantiate the XGBClassifier\n",
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)\n",
    "# Fit the classifier to the training set\n",
    "xg_cl.fit(X_train, y_train)\n",
    "# Predict the labels of the test set\n",
    "preds = xg_cl.predict(X_test)\n",
    "# Compute the accuracy: accuracy\n",
    "accuracy = float(np.sum(preds == y_test)) / y_test.shape[0]\n",
    "print(\"accuracy: %f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e05a804116a692",
   "metadata": {},
   "source": [
    "### What is a decision tree?\n",
    "\n",
    "Because XGBoost is an ensemble method, it relies on the use of many decision trees to make predictions. So, what is a decision tree?\n",
    "\n",
    "Each node contains a question, with only two possible choices. At the very bottom of the tree, there is a single possible decision. Every possible path will lead to a decision.\n",
    "\n",
    "#### Decision trees as base learners\n",
    "\n",
    "Base learner - individual learning algorithm in an ensemble algorithm\n",
    "Composed of a series of binary questions\n",
    "Predictions happen at the \"leaves\" of the tree\n",
    "\n",
    "### Decision trees and CART\n",
    "\n",
    "Constructed iteratively (one decision at a time), until a stopping criterion is met\n",
    "\n",
    "#### Individual decision trees\n",
    "\n",
    "Are low bias, high variance in general. This means that they are very good at learning relationships but they tend to overfit the training data. And often they do not generalize well to new data.\n",
    "\n",
    "#### CART: Classification and Regression Trees\n",
    "\n",
    "Each leaf **always** contains a real-valued score regardless of whether the tree is used for classification or regression\n",
    "The real-valued scores can later be tresholded to convert into categories for classification problems if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e58983adbc888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "class_data = pd.read_csv('class_data.csv')\n",
    "# Split the entire dataset into features (X) and target (y)\n",
    "X, y = class_data.iloc[:, :-1], class_data.iloc[:, -1]\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=123)\n",
    "\n",
    "# Instantiate the classifier: dt_clf_4\n",
    "dt_clf_4 = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "dt_clf_4.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred_4\n",
    "y_pred_4 = dt_clf_4.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the predictions: accuracy\n",
    "accuracy = float(np.sum(y_pred_4 == y_test)) / y_test.shape[0]\n",
    "print(\"accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24715e9cde7ab101",
   "metadata": {},
   "source": [
    "### What is Boosting?\n",
    "\n",
    "- Not a specific machine learning algorithm\n",
    "- Concept that can be applied to a set of machine learning models: \"Meta-algorithm\"\n",
    "- Ensemble meta-algorithm used to convert many weak learners into a strong learner\n",
    "\n",
    "#### Weak learners and strong learners\n",
    "\n",
    "- **Weak learner**: ML algorithm that is slightly better than chance\n",
    "    - Example: Decision tree whose predictions are slightly better than 50%\n",
    "    - Boosting converts a collection of weak learners into a strong learner\n",
    "- **Strong learner**: Any algorithm that can be tuned to achieve good performance\n",
    "\n",
    "#### How boosting is accomplished\n",
    "\n",
    "- Iteratively learning a set of weak models on subsets of the data\n",
    "- Weighing each weak prediction according to each weak learner's performance\n",
    "- Combine the weighted predictions to obtain a single weighted prediction... that is much stronger than the individual ones\n",
    "\n",
    "#### Model evaluation through cross-validation\n",
    "\n",
    "- Cross-validation: Robust method for estimating the performance of a model on unseen data\n",
    "- Generates many none-overlapping train/test splits on training data\n",
    "- Reports the average test set performance across all data splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb5f44006f0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "churn_data = pd.read_csv('churn_data.csv')\n",
    "\n",
    "churn_dmatrix = xgb.DMatrix(data=churn_data.iloc[:, :-1], label=churn_data.month_5_still_here)\n",
    "params = {\"objective\": \"binary:logistic\", \"max_depth\": 4}\n",
    "# nfold: number of cross-validation folds\n",
    "# num_boost_round: number of trees we build\n",
    "# metrics: metric to be computed (error for accuracy)\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=4, num_boost_round=10, metrics=\"error\", as_pandas=True)\n",
    "print(\"Accuracy: %f\" % ((1 - cv_results[\"test-error-mean\"]).iloc[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f409d20e33fd26",
   "metadata": {},
   "source": [
    "### When to use XGBoost\n",
    "\n",
    "- Large number of training samples\n",
    "    - Greater than 1000 training samples and less than 100 features\n",
    "    - The number of features < number of training samples \n",
    "- You have a mixture of categorical and numeric features\n",
    "  - Or just numeric features\n",
    "\n",
    "### When to NOT use XGBoost\n",
    "- Image recognition\n",
    "- Computer vision\n",
    "- Natural language processing and understanding problems\n",
    "- When the number of training samples is significantly smaller than the number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a2f1cac1f5c53",
   "metadata": {},
   "source": [
    "## Demo\n",
    "\n",
    "We will be working with the Diamonds dataset throughout the tutorial. It is built into the `Seaborn` library, or alternatively, you can also download it from [Kaggle](https://www.kaggle.com/datasets/shivam2503/diamonds?resource=download). It has a nice combination of numeric and categorical features and over 50k observations that we can comfortably showcase all the advantages of XGBoost.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aadab17f84fbc76a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:14:37.542054Z",
     "start_time": "2024-06-06T01:14:37.482164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "diamonds = sns.load_dataset(\"diamonds\")\n",
    "\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ded12e82d0d27b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:14:41.087792Z",
     "start_time": "2024-06-06T01:14:41.081793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53940, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a924df7fad679",
   "metadata": {},
   "source": [
    "In a typical real-world project, you would want to spend a lot more time exploring the dataset and visualizing its features. But since this data comes built-in to Seaborn, it is relatively clean.\n",
    "\n",
    "So, we will just look at the 5-number summary of the numeric and categorical features and get going. You can spend a few moments to familiarize yourself with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d022d2f2a6732c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:14:44.984652Z",
     "start_time": "2024-06-06T01:14:44.955649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797940</td>\n",
       "      <td>61.749405</td>\n",
       "      <td>57.457184</td>\n",
       "      <td>3932.799722</td>\n",
       "      <td>5.731157</td>\n",
       "      <td>5.734526</td>\n",
       "      <td>3.538734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474011</td>\n",
       "      <td>1.432621</td>\n",
       "      <td>2.234491</td>\n",
       "      <td>3989.439738</td>\n",
       "      <td>1.121761</td>\n",
       "      <td>1.142135</td>\n",
       "      <td>0.705699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2401.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>5324.250000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>18823.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>31.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat         depth         table         price             x  \\\n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
       "mean       0.797940     61.749405     57.457184   3932.799722      5.731157   \n",
       "std        0.474011      1.432621      2.234491   3989.439738      1.121761   \n",
       "min        0.200000     43.000000     43.000000    326.000000      0.000000   \n",
       "25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n",
       "50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n",
       "75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \n",
       "max        5.010000     79.000000     95.000000  18823.000000     10.740000   \n",
       "\n",
       "                  y             z  \n",
       "count  53940.000000  53940.000000  \n",
       "mean       5.734526      3.538734  \n",
       "std        1.142135      0.705699  \n",
       "min        0.000000      0.000000  \n",
       "25%        4.720000      2.910000  \n",
       "50%        5.710000      3.530000  \n",
       "75%        6.540000      4.040000  \n",
       "max       58.900000     31.800000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5210cdbf0be2e5d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:14:48.352336Z",
     "start_time": "2024-06-06T01:14:48.338551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>SI1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>21551</td>\n",
       "      <td>11292</td>\n",
       "      <td>13065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cut  color clarity\n",
       "count   53940  53940   53940\n",
       "unique      5      7       8\n",
       "top     Ideal      G     SI1\n",
       "freq    21551  11292   13065"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "diamonds.describe(exclude=np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b42f09ec3ae0d",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "After you are done with exploration, the first step in any project is framing the machine learning problem and extracting the feature and target arrays based on the dataset.\n",
    "\n",
    "In this tutorial, we will first try to predict diamond prices using their physical measurements, so our target will be the price column.\n",
    "\n",
    "So, we are isolating the features into X and the target into y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39cf85c8bf5ffbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:14:50.793649Z",
     "start_time": "2024-06-06T01:14:50.772652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat       float64\n",
       "cut        category\n",
       "color      category\n",
       "clarity    category\n",
       "depth       float64\n",
       "table       float64\n",
       "x           float64\n",
       "y           float64\n",
       "z           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract feature and target arrays\n",
    "X, y = diamonds.drop('price', axis=1), diamonds[['price']]\n",
    "\n",
    "# Extract text features\n",
    "cats = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "# Convert to Pandas category\n",
    "for col in cats:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8812f06b2a64b1bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:14:56.697774Z",
     "start_time": "2024-06-06T01:14:56.203647Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=123)\n",
    "\n",
    "# Create regression matrices\n",
    "dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f3495041f2f0a",
   "metadata": {},
   "source": [
    "After building the DMatrices, you should choose a value for the `objective` parameter. It tells XGBoost the machine learning problem you are trying to solve and what metrics or loss functions to use to solve that problem.\n",
    "\n",
    "For example, to predict diamond prices, which is a regression problem, you can use the common `reg:squarederror` objective. Usually, the name of the objective also contains the name of the loss function for the problem. For regression, it is common to use Root Mean Squared Error, which minimizes the square root of the squared sum of the differences between actual and predicted values. Here is how the metric would look like when implemented in NumPy:\n",
    "\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "mse = np.mean((actual - predicted) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "```\n",
    "\n",
    "We’ll learn classification objectives later in the tutorial.\n",
    "\n",
    "A note on the difference between a loss function and a performance metric: A loss function is used by machine learning models to minimize the differences between the actual (ground truth) values and model predictions. On the other hand, a metric (or metrics) is chosen by the machine learning engineer to measure the similarity between ground truth and model predictions.\n",
    "\n",
    "In short, a loss function should be minimized while a metric should be maximized. A loss function is used during training to guide the model on where to improve. A metric is used during evaluation to measure overall performance.\n",
    "\n",
    "### Training the model\n",
    "\n",
    "Inside this initial `params`, we are also setting `tree_method` to `gpu_hist`, which enables GPU acceleration. If you don't have a GPU, you can omit the parameter or set it to `hist`.\n",
    "\n",
    "Now, we set another parameter called `num_boost_round`, which stands for number of boosting rounds. Internally, XGBoost minimizes the loss function RMSE in small incremental rounds (more on this later). This parameter specifies the amount of those rounds.\n",
    "\n",
    "The ideal number of rounds is found through hyperparameter tuning. For now, we will just set it to 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122f7ed4908a2710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:15:03.859404Z",
     "start_time": "2024-06-06T01:15:02.851667Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"gpu_hist\"}\n",
    "n = 100\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain_reg,\n",
    "    num_boost_round=n,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "896a32853806b59e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:15:05.708439Z",
     "start_time": "2024-06-06T01:15:05.694441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the base model: 542.265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "preds = model.predict(dtest_reg)\n",
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "print(f\"RMSE of the base model: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad1f322eb32e701",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "Training a machine learning model is like launching a rocket into space. You can control everything about the model up to the launch, but once it does, all you can do is stand by and wait for it to finish.\n",
    "\n",
    "But the problem with our current training process is that we can’t even watch where the model is going. To solve this, we will use evaluation arrays that allow us to see model performance as it gets improved incrementally across boosting rounds.\n",
    "\n",
    "First, let’s set up the parameters again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4dee71d53588560",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:15:09.583711Z",
     "start_time": "2024-06-06T01:15:09.568712Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"gpu_hist\"}\n",
    "n = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6402ccaca7385",
   "metadata": {},
   "source": [
    "Next, we create a list of two tuples that each contain two elements. The first element is the array for the model to evaluate, and the second is the array’s name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a80aede26a181a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:15:13.678667Z",
     "start_time": "2024-06-06T01:15:13.670666Z"
    }
   },
   "outputs": [],
   "source": [
    "evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acd0fa85213e110",
   "metadata": {},
   "source": [
    "When we pass this array to the evals parameter of xgb.train, we will see the model performance after each boosting round:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99c308d0713111c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:15:22.111900Z",
     "start_time": "2024-06-06T01:15:21.042656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2862.31146\tvalidation-rmse:2840.68834\n",
      "[1]\ttrain-rmse:2082.81862\tvalidation-rmse:2065.21072\n",
      "[2]\ttrain-rmse:1549.44507\tvalidation-rmse:1536.71389\n",
      "[3]\ttrain-rmse:1187.07459\tvalidation-rmse:1176.80318\n",
      "[4]\ttrain-rmse:945.91339\tvalidation-rmse:939.61269\n",
      "[5]\ttrain-rmse:790.74365\tvalidation-rmse:791.39691\n",
      "[6]\ttrain-rmse:691.02783\tvalidation-rmse:696.96497\n",
      "[7]\ttrain-rmse:630.99900\tvalidation-rmse:644.34523\n",
      "[8]\ttrain-rmse:590.14399\tvalidation-rmse:607.29011\n",
      "[9]\ttrain-rmse:564.79697\tvalidation-rmse:585.92024\n",
      "[10]\ttrain-rmse:548.30676\tvalidation-rmse:572.75567\n",
      "[11]\ttrain-rmse:536.77530\tvalidation-rmse:564.87578\n",
      "[12]\ttrain-rmse:529.14333\tvalidation-rmse:559.05668\n",
      "[13]\ttrain-rmse:522.04003\tvalidation-rmse:554.92832\n",
      "[14]\ttrain-rmse:516.57524\tvalidation-rmse:551.69600\n",
      "[15]\ttrain-rmse:510.55122\tvalidation-rmse:548.89999\n",
      "[16]\ttrain-rmse:507.40026\tvalidation-rmse:548.23401\n",
      "[17]\ttrain-rmse:501.95883\tvalidation-rmse:547.28474\n",
      "[18]\ttrain-rmse:497.47550\tvalidation-rmse:545.46888\n",
      "[19]\ttrain-rmse:494.33895\tvalidation-rmse:544.61675\n",
      "[20]\ttrain-rmse:492.54153\tvalidation-rmse:544.03410\n",
      "[21]\ttrain-rmse:487.93013\tvalidation-rmse:543.95288\n",
      "[22]\ttrain-rmse:485.97002\tvalidation-rmse:543.47857\n",
      "[23]\ttrain-rmse:482.25221\tvalidation-rmse:542.93880\n",
      "[24]\ttrain-rmse:479.15309\tvalidation-rmse:542.18649\n",
      "[25]\ttrain-rmse:476.40775\tvalidation-rmse:541.74283\n",
      "[26]\ttrain-rmse:475.11402\tvalidation-rmse:541.43717\n",
      "[27]\ttrain-rmse:471.90981\tvalidation-rmse:540.88683\n",
      "[28]\ttrain-rmse:469.69584\tvalidation-rmse:540.87151\n",
      "[29]\ttrain-rmse:468.36940\tvalidation-rmse:540.87322\n",
      "[30]\ttrain-rmse:466.34892\tvalidation-rmse:540.94242\n",
      "[31]\ttrain-rmse:464.24571\tvalidation-rmse:540.04888\n",
      "[32]\ttrain-rmse:462.92476\tvalidation-rmse:539.88213\n",
      "[33]\ttrain-rmse:459.30503\tvalidation-rmse:540.84489\n",
      "[34]\ttrain-rmse:456.43428\tvalidation-rmse:540.81359\n",
      "[35]\ttrain-rmse:454.47846\tvalidation-rmse:540.73125\n",
      "[36]\ttrain-rmse:452.71199\tvalidation-rmse:540.91799\n",
      "[37]\ttrain-rmse:451.60931\tvalidation-rmse:540.88244\n",
      "[38]\ttrain-rmse:451.35975\tvalidation-rmse:540.66947\n",
      "[39]\ttrain-rmse:448.82069\tvalidation-rmse:540.96995\n",
      "[40]\ttrain-rmse:444.98078\tvalidation-rmse:541.91808\n",
      "[41]\ttrain-rmse:443.36698\tvalidation-rmse:542.04526\n",
      "[42]\ttrain-rmse:440.99154\tvalidation-rmse:541.62107\n",
      "[43]\ttrain-rmse:438.59322\tvalidation-rmse:541.59148\n",
      "[44]\ttrain-rmse:438.37835\tvalidation-rmse:541.44746\n",
      "[45]\ttrain-rmse:437.60813\tvalidation-rmse:541.29961\n",
      "[46]\ttrain-rmse:436.05224\tvalidation-rmse:541.84028\n",
      "[47]\ttrain-rmse:435.44857\tvalidation-rmse:541.71412\n",
      "[48]\ttrain-rmse:431.88238\tvalidation-rmse:542.32740\n",
      "[49]\ttrain-rmse:431.20460\tvalidation-rmse:542.42310\n",
      "[50]\ttrain-rmse:430.19810\tvalidation-rmse:542.52170\n",
      "[51]\ttrain-rmse:429.24718\tvalidation-rmse:542.22803\n",
      "[52]\ttrain-rmse:427.53949\tvalidation-rmse:542.06358\n",
      "[53]\ttrain-rmse:426.27503\tvalidation-rmse:542.03018\n",
      "[54]\ttrain-rmse:424.30321\tvalidation-rmse:541.25275\n",
      "[55]\ttrain-rmse:421.09088\tvalidation-rmse:542.29587\n",
      "[56]\ttrain-rmse:420.66679\tvalidation-rmse:542.16209\n",
      "[57]\ttrain-rmse:418.80020\tvalidation-rmse:542.59992\n",
      "[58]\ttrain-rmse:417.32555\tvalidation-rmse:542.67473\n",
      "[59]\ttrain-rmse:415.87494\tvalidation-rmse:543.00040\n",
      "[60]\ttrain-rmse:414.58319\tvalidation-rmse:542.93248\n",
      "[61]\ttrain-rmse:414.29693\tvalidation-rmse:542.91012\n",
      "[62]\ttrain-rmse:413.23737\tvalidation-rmse:543.41531\n",
      "[63]\ttrain-rmse:412.06510\tvalidation-rmse:542.96015\n",
      "[64]\ttrain-rmse:410.40701\tvalidation-rmse:542.98286\n",
      "[65]\ttrain-rmse:409.78597\tvalidation-rmse:542.65959\n",
      "[66]\ttrain-rmse:407.46891\tvalidation-rmse:542.89223\n",
      "[67]\ttrain-rmse:406.32993\tvalidation-rmse:542.87740\n",
      "[68]\ttrain-rmse:405.27918\tvalidation-rmse:543.02311\n",
      "[69]\ttrain-rmse:405.19127\tvalidation-rmse:542.98165\n",
      "[70]\ttrain-rmse:403.43149\tvalidation-rmse:542.54281\n",
      "[71]\ttrain-rmse:402.49126\tvalidation-rmse:542.50265\n",
      "[72]\ttrain-rmse:401.02923\tvalidation-rmse:542.65585\n",
      "[73]\ttrain-rmse:399.69322\tvalidation-rmse:542.60444\n",
      "[74]\ttrain-rmse:399.24742\tvalidation-rmse:542.62855\n",
      "[75]\ttrain-rmse:398.70343\tvalidation-rmse:542.50444\n",
      "[76]\ttrain-rmse:397.35219\tvalidation-rmse:542.43515\n",
      "[77]\ttrain-rmse:393.94142\tvalidation-rmse:542.25136\n",
      "[78]\ttrain-rmse:393.42843\tvalidation-rmse:542.11650\n",
      "[79]\ttrain-rmse:391.81995\tvalidation-rmse:542.49049\n",
      "[80]\ttrain-rmse:390.37661\tvalidation-rmse:542.33747\n",
      "[81]\ttrain-rmse:389.22420\tvalidation-rmse:542.23804\n",
      "[82]\ttrain-rmse:388.93016\tvalidation-rmse:542.10702\n",
      "[83]\ttrain-rmse:387.59741\tvalidation-rmse:541.89017\n",
      "[84]\ttrain-rmse:385.56991\tvalidation-rmse:542.29583\n",
      "[85]\ttrain-rmse:384.25435\tvalidation-rmse:542.38721\n",
      "[86]\ttrain-rmse:383.90104\tvalidation-rmse:542.18699\n",
      "[87]\ttrain-rmse:383.68148\tvalidation-rmse:542.19263\n",
      "[88]\ttrain-rmse:381.71592\tvalidation-rmse:542.56930\n",
      "[89]\ttrain-rmse:381.51438\tvalidation-rmse:542.71948\n",
      "[90]\ttrain-rmse:380.76824\tvalidation-rmse:542.74332\n",
      "[91]\ttrain-rmse:379.26777\tvalidation-rmse:542.81469\n",
      "[92]\ttrain-rmse:379.18449\tvalidation-rmse:542.76303\n",
      "[93]\ttrain-rmse:379.01749\tvalidation-rmse:542.69558\n",
      "[94]\ttrain-rmse:378.53760\tvalidation-rmse:542.72125\n",
      "[95]\ttrain-rmse:377.59881\tvalidation-rmse:542.94381\n",
      "[96]\ttrain-rmse:377.08720\tvalidation-rmse:542.66414\n",
      "[97]\ttrain-rmse:376.81128\tvalidation-rmse:542.61381\n",
      "[98]\ttrain-rmse:375.37198\tvalidation-rmse:542.45871\n",
      "[99]\ttrain-rmse:374.67207\tvalidation-rmse:542.26454\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain_reg,\n",
    "    num_boost_round=n,\n",
    "    evals=evals,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5b1228514101563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:16:00.999041Z",
     "start_time": "2024-06-06T01:15:25.207612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2862.31146\tvalidation-rmse:2840.68834\n",
      "[500]\ttrain-rmse:195.16395\tvalidation-rmse:562.24713\n",
      "[1000]\ttrain-rmse:119.62424\tvalidation-rmse:570.01617\n",
      "[1500]\ttrain-rmse:82.38357\tvalidation-rmse:572.87333\n",
      "[2000]\ttrain-rmse:60.83733\tvalidation-rmse:575.02089\n",
      "[2500]\ttrain-rmse:46.95207\tvalidation-rmse:576.43277\n",
      "[3000]\ttrain-rmse:36.08419\tvalidation-rmse:577.29667\n",
      "[3500]\ttrain-rmse:29.11954\tvalidation-rmse:577.78109\n",
      "[4000]\ttrain-rmse:23.75240\tvalidation-rmse:578.22335\n",
      "[4500]\ttrain-rmse:20.01431\tvalidation-rmse:578.47206\n",
      "[4999]\ttrain-rmse:17.15337\tvalidation-rmse:578.63708\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "\n",
    "evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n",
    "\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain_reg,\n",
    "    num_boost_round=n,\n",
    "    evals=evals,\n",
    "    verbose_eval=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b44bbe0e2aaf2243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:16:05.119628Z",
     "start_time": "2024-06-06T01:16:03.354602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2862.31146\tvalidation-rmse:2840.68834\n",
      "[50]\ttrain-rmse:430.19810\tvalidation-rmse:542.52170\n",
      "[100]\ttrain-rmse:372.89833\tvalidation-rmse:541.72131\n",
      "[150]\ttrain-rmse:327.91646\tvalidation-rmse:549.48379\n",
      "[181]\ttrain-rmse:309.51202\tvalidation-rmse:550.20288\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "\n",
    "evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n",
    "\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain_reg,\n",
    "    num_boost_round=n,\n",
    "    evals=evals,\n",
    "    verbose_eval=50,\n",
    "    # Activate early stopping\n",
    "    early_stopping_rounds=150\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a798657b3e07ac",
   "metadata": {},
   "source": [
    "### XGBoost Cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8998159a6377ef64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:16:10.073665Z",
     "start_time": "2024-06-06T01:16:06.887667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2863.735582</td>\n",
       "      <td>5.736820</td>\n",
       "      <td>2866.800179</td>\n",
       "      <td>28.367405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2083.181962</td>\n",
       "      <td>5.689362</td>\n",
       "      <td>2089.536563</td>\n",
       "      <td>19.794082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1547.302833</td>\n",
       "      <td>4.178947</td>\n",
       "      <td>1557.401456</td>\n",
       "      <td>17.321109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1183.037644</td>\n",
       "      <td>3.214807</td>\n",
       "      <td>1198.799702</td>\n",
       "      <td>16.904746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>941.048091</td>\n",
       "      <td>3.030368</td>\n",
       "      <td>961.480079</td>\n",
       "      <td>15.845508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0      2863.735582        5.736820     2866.800179      28.367405\n",
       "1      2083.181962        5.689362     2089.536563      19.794082\n",
       "2      1547.302833        4.178947     1557.401456      17.321109\n",
       "3      1183.037644        3.214807     1198.799702      16.904746\n",
       "4       941.048091        3.030368      961.480079      15.845508"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"gpu_hist\"}\n",
    "n = 1000\n",
    "\n",
    "results = xgb.cv(\n",
    "    params, dtrain_reg,\n",
    "    num_boost_round=n,\n",
    "    nfold=5,\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d26c914bb29a4ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:16:13.113650Z",
     "start_time": "2024-06-06T01:16:13.100649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 548.75\n"
     ]
    }
   ],
   "source": [
    "best_rmse = results['test-rmse-mean'].min()\n",
    "print(f\"Best RMSE: {best_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b52d275fad349",
   "metadata": {},
   "source": [
    "Note that this method of cross-validation is used to see the true performance of the model. Once satisfied with its score, you must retrain it on the full data before deployment."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T02:30:42.255606Z",
     "start_time": "2024-06-06T01:29:08.313610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    \"max_depth\": [3, 4, 5, 6, 8, 10, 12, 15],\n",
    "    \"min_child_weight\": [1, 3, 5, 7],\n",
    "    \"gamma\": [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "    \"colsample_bytree\": [0.3, 0.4, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "search = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "search.fit(X_train.drop(columns=cats), y_train)\n",
    "\n",
    "print(search.best_params_)"
   ],
   "id": "42433a1185633348",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7, 'gamma': 0.0, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 7}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Values of hyperparameters that maximize the model's performance.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"gamma\": 0.0,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_weight\": 7\n",
    "}\n",
    "```\n",
    "\n",
    "- `colsample_bytree`: `0.7`: This means that each tree will randomly select 70% of the features before it starts to grow. This level of randomness helps prevent overfitting.\n",
    "- `gamma`: `0.0`: This is the specified minimum loss reduction required to make a further partition on a leaf node of the tree. A value of 0.0 indicates that there is no minimum loss reduction required, which may lead to more complex trees.\n",
    "- `learning_rate`: `0.05`: This is your learning rate (or eta). It signifies a relatively slower learning rate. Slower learning rates often lead to better performance but are slower to train.\n",
    "- `max_depth`: `8`: This is the maximum depth per tree. Deeper trees can model more complex relationships by adding more nodes, but they also risk overfitting.\n",
    "- `min_child_weight`: `7`: This is the minimum sum of instance weight (hessian) needed in a child. This parameter is used to control overfitting. The larger the value, the more conservative the algorithm will be. A value of 7 means that splitting a node will only get considered if it contains at least seven instances weighted by their Hessian (second order gradient)."
   ],
   "id": "852f9d237d9f6c18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T02:54:23.391868Z",
     "start_time": "2024-06-06T02:54:22.366872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimal_params = {'colsample_bytree': 0.7,\n",
    "                  'gamma': 0.0,\n",
    "                  'learning_rate': 0.05,\n",
    "                  'max_depth': 8,\n",
    "                  'min_child_weight': 7,\n",
    "                  'objective': 'reg:squarederror'}\n",
    "n = 10_000\n",
    "\n",
    "model = xgb.train(\n",
    "    params=optimal_params,\n",
    "    dtrain=dtrain_reg,\n",
    "    num_boost_round=n,\n",
    "    evals=evals,\n",
    "    verbose_eval=50,\n",
    "    # Activate early stopping\n",
    "    early_stopping_rounds=150)\n"
   ],
   "id": "c4c023bb90e1f8b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3801.30313\tvalidation-rmse:3784.05907\n",
      "[50]\ttrain-rmse:620.07539\tvalidation-rmse:651.29847\n",
      "[100]\ttrain-rmse:451.56478\tvalidation-rmse:526.75196\n",
      "[150]\ttrain-rmse:421.70235\tvalidation-rmse:520.71008\n",
      "[200]\ttrain-rmse:400.34397\tvalidation-rmse:519.80790\n",
      "[250]\ttrain-rmse:387.77836\tvalidation-rmse:520.10523\n",
      "[300]\ttrain-rmse:377.73299\tvalidation-rmse:520.13723\n",
      "[350]\ttrain-rmse:369.35932\tvalidation-rmse:520.40862\n",
      "[368]\ttrain-rmse:366.30248\tvalidation-rmse:520.98613\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And we can see base score this again:",
   "id": "8687db3802d7e595"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T02:54:25.951935Z",
     "start_time": "2024-06-06T02:54:25.910936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate predictions\n",
    "preds = model.predict(dtest_reg)\n",
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "print(f\"RMSE of the base model: {rmse:.3f}\")"
   ],
   "id": "d44022b40d7d561e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the base model: 521.023\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Root Mean Squared Error value of `521.023` means that, on average, the model's predicted values are approximately `521` units away from the actual values.",
   "id": "db9d73db4f66a3f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T02:55:33.062371Z",
     "start_time": "2024-06-06T02:55:30.063373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = xgb.cv(\n",
    "    params=optimal_params,\n",
    "    dtrain=dtrain_reg,\n",
    "    num_boost_round=n,\n",
    "    nfold=5,\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "\n",
    "best_rmse = results['test-rmse-mean'].min()\n",
    "print(f\"Best RMSE: {best_rmse:.3f}\")"
   ],
   "id": "686e1676169bc2b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 543.421\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The 'best RMSE' of `543.421` was the best score observed during the CV process, meaning it was the smallest average RMSE across testing on all different folds. \n",
    "\n",
    "This is often a more reliable indicator of how your model will perform on unseen data, because it averages over several different splits of the data rather than relying on a single split."
   ],
   "id": "b0e3e2f48b5f5e3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T03:03:49.363651Z",
     "start_time": "2024-06-06T03:03:49.350654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, preds)\n",
    "print(f'R-Squared: {r2:.5f}')"
   ],
   "id": "ffce45237f7ddfc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared: 0.98283\n"
     ]
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
